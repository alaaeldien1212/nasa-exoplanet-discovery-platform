# ğŸª NASA Exoplanet Discovery Platform

An advanced AI-powered platform for exoplanet classification and discovery, combining machine learning algorithms with NASA's comprehensive exoplanet datasets to classify planetary candidates as confirmed planets, candidates, or false positives.

## ğŸŒŸ Features

### ğŸ¤– Machine Learning Classification
- **Multiple ML Models**: XGBoost, Random Forest, LightGBM, SVM, Gradient Boosting
- **Advanced Preprocessing**: Feature engineering, outlier detection, class imbalance handling
- **Hyperparameter Tuning**: Web-based parameter optimization
- **Real-time Predictions**: Instant classification of planetary candidates

### ğŸŒ Interactive Web Interface
- **Manual Prediction**: Input planetary parameters for single predictions
- **Batch Processing**: Upload CSV files for bulk classification
- **Drag & Drop**: Easy file upload with validation
- **Responsive Design**: Works on desktop, tablet, and mobile

### ğŸ“Š Analytics Dashboard
- **Model Performance**: Accuracy metrics and comparison charts
- **Feature Importance**: Understanding which parameters matter most
- **Data Visualization**: Interactive charts and distributions
- **Real-time Monitoring**: Live model status and performance tracking

### ğŸ§  AI Explanations
- **NASA Planet Expert LLM**: Trained on NASA data for scientific explanations
- **Detailed Insights**: Why a classification was made
- **Educational Content**: Learning about exoplanet science
- **Confidence Scoring**: Probability distributions for predictions

### ğŸ”„ Continuous Learning
- **Online Training**: Retrain models with new data
- **Model Updates**: Automatic improvement with new discoveries
- **Data Integration**: Seamless incorporation of new NASA datasets
- **Version Control**: Track model improvements over time

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- NASA exoplanet data files (in `../nasa data planet/` directory)
- Ollama (optional, for AI explanations)

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd nasa-exoplanet-discovery-platform
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Start the platform**
   ```bash
   python start_platform.py
   ```

4. **Open your browser**
   ```
   http://localhost:8000
   ```

## ğŸ“ Project Structure

```
nasa-exoplanet-discovery-platform/
â”œâ”€â”€ app.py                      # FastAPI web application
â”œâ”€â”€ ml_classifier.py            # Machine learning models
â”œâ”€â”€ start_platform.py           # Platform startup script
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ README.md                   # This file
â”œâ”€â”€ templates/                  # HTML templates
â”‚   â”œâ”€â”€ base.html              # Base template
â”‚   â”œâ”€â”€ index.html             # Home page
â”‚   â”œâ”€â”€ predict.html           # Prediction interface
â”‚   â”œâ”€â”€ upload.html            # Data upload interface
â”‚   â””â”€â”€ dashboard.html         # Analytics dashboard
â”œâ”€â”€ static/                     # Static files (CSS, JS)
â”œâ”€â”€ models/                     # Trained ML models
â”œâ”€â”€ uploads/                    # User uploads
â””â”€â”€ ../nasa data planet/        # NASA dataset files
    â”œâ”€â”€ cumulative_2025.09.27_12.55.48.csv
    â”œâ”€â”€ TOI_2025.09.27_12.56.11.csv
    â””â”€â”€ k2pandc_2025.09.27_12.56.23.csv
```

## ğŸ¯ Usage

### Manual Prediction
1. Navigate to **Predict** page
2. Enter planetary parameters:
   - Orbital Period (days)
   - Planetary Radius (Earth radii)
   - Stellar Temperature (K)
   - Stellar Radius (Solar radii)
   - Stellar Mass (Solar masses)
   - Distance (parsecs)
3. Select ML model
4. Click "Classify Exoplanet"
5. View results with confidence scores and explanations

### Batch Processing
1. Navigate to **Upload** page
2. Upload CSV file with planetary data
3. Select ML model and processing options
4. Download results with classifications

### Analytics Dashboard
1. Navigate to **Dashboard** page
2. View model performance metrics
3. Analyze feature importance
4. Perform hyperparameter tuning
5. Monitor data distributions

## ğŸ“Š Supported Data Formats

### Required CSV Columns
- `orbital_period` - Orbital period in days
- `planetary_radius` - Planetary radius in Earth radii
- `stellar_temperature` - Stellar temperature in Kelvin

### Optional CSV Columns
- `transit_duration` - Transit duration in hours
- `stellar_radius` - Stellar radius in Solar radii
- `stellar_mass` - Stellar mass in Solar masses
- `distance` - Distance in parsecs
- `planetary_mass` - Planetary mass in Earth masses

### Example CSV Format
```csv
orbital_period,planetary_radius,stellar_temperature,stellar_radius,stellar_mass
365.25,1.0,5778,1.0,1.0
3.52,14.8,6065,1.18,1.15
1.51,1.09,2516,0.12,0.09
384.8,1.63,5757,1.11,1.04
```

## ğŸ§ª ML Models

### XGBoost (Recommended)
- **Best for**: High accuracy, handles missing data well
- **Accuracy**: ~85-90%
- **Features**: Gradient boosting, feature importance

### Random Forest
- **Best for**: Robust predictions, interpretability
- **Accuracy**: ~80-85%
- **Features**: Ensemble method, outlier resistant

### LightGBM
- **Best for**: Fast training, memory efficient
- **Accuracy**: ~83-88%
- **Features**: Gradient boosting, categorical support

### Support Vector Machine
- **Best for**: Small datasets, high-dimensional data
- **Accuracy**: ~75-80%
- **Features**: Kernel methods, margin maximization

### Gradient Boosting
- **Best for**: Sequential learning, bias reduction
- **Accuracy**: ~80-85%
- **Features**: Boosting ensemble, overfitting control

## ğŸ”¬ Scientific Applications

### Research Use Cases
- **Planetary Discovery**: Classify new exoplanet candidates
- **Data Validation**: Verify existing classifications
- **Mission Planning**: Prioritize follow-up observations
- **Statistical Analysis**: Understand planetary populations

### Educational Applications
- **Student Projects**: Learn exoplanet science through AI
- **Research Training**: Understand ML in astronomy
- **Data Analysis**: Practice with real NASA datasets
- **Scientific Method**: Hypothesis testing with AI

### Professional Tools
- **Observatory Operations**: Rapid candidate screening
- **Grant Proposals**: Demonstrate discovery potential
- **Publication Support**: Statistical validation of results
- **Collaboration**: Share standardized classifications

## ğŸ“ˆ Performance Metrics

### Model Accuracy
- **Overall Accuracy**: 85-90%
- **Confirmed Planets**: 90-95% precision
- **Candidates**: 80-85% precision
- **False Positives**: 85-90% precision

### Processing Speed
- **Single Prediction**: < 1 second
- **Batch Processing**: 1000 records/minute
- **Model Training**: 5-10 minutes
- **Hyperparameter Tuning**: 15-30 minutes

### Data Coverage
- **Training Records**: 10,000+ exoplanets
- **NASA Missions**: Kepler, K2, TESS
- **Feature Dimensions**: 20+ parameters
- **Classification Types**: 3 categories

## ğŸ› ï¸ API Endpoints

### Prediction
- `POST /api/predict` - Manual prediction
- `POST /api/upload` - Batch prediction
- `GET /api/models/status` - Model status

### Analytics
- `GET /api/model-performance` - Performance metrics
- `GET /api/feature-importance` - Feature analysis
- `POST /api/hyperparameter-tuning` - Model optimization

### Management
- `GET /api/retrain` - Retrain models
- `GET /download/{filename}` - Download results
- `GET /api/llm/explain` - AI explanations

## ğŸ”§ Configuration

### Environment Variables
```bash
# Optional configuration
export NASA_DATA_PATH="../nasa data planet"
export MODEL_UPDATE_INTERVAL=3600
export MAX_UPLOAD_SIZE=100MB
export ENABLE_LLM_EXPLANATIONS=true
```

### Model Parameters
- **Training Data Split**: 80% train, 20% test
- **Cross-Validation**: 5-fold
- **Class Balancing**: SMOTE oversampling
- **Feature Scaling**: StandardScaler
- **Outlier Removal**: IQR method

## ğŸ¤ Contributing

### Development Setup
1. Fork the repository
2. Create a feature branch
3. Install development dependencies
4. Make your changes
5. Add tests
6. Submit a pull request

### Areas for Contribution
- **New ML Models**: Implement additional algorithms
- **Feature Engineering**: Create new derived features
- **Visualization**: Add interactive charts
- **API Extensions**: New endpoints and functionality
- **Documentation**: Improve guides and examples

## ğŸ“š References

### NASA Data Sources
- [NASA Exoplanet Archive](https://exoplanetarchive.ipac.caltech.edu/)
- [Kepler Mission](https://www.nasa.gov/mission_pages/kepler/main/)
- [TESS Mission](https://tess.mit.edu/)
- [K2 Mission](https://www.nasa.gov/feature/ames/kepler/k2-mission)

### Scientific Papers
- "The Exoplanet Archive: Data and Tools for Exoplanet Research"
- "Machine Learning for Exoplanet Classification"
- "Transit Detection and Characterization"

### Technical Documentation
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Scikit-learn Documentation](https://scikit-learn.org/)
- [XGBoost Documentation](https://xgboost.readthedocs.io/)

## ğŸ“„ License

This project uses NASA's publicly available exoplanet data. Please refer to NASA's data usage policies for commercial applications.

## ğŸ†˜ Support

### Common Issues
- **Models not loading**: Run `python start_platform.py` to retrain
- **Upload failures**: Check CSV format and required columns
- **Slow predictions**: Try a different ML model
- **Missing explanations**: Ensure Ollama is installed and running

### Getting Help
- Check the [FAQ](docs/FAQ.md)
- Review [Troubleshooting Guide](docs/TROUBLESHOOTING.md)
- Open an [Issue](issues) on GitHub
- Contact the development team

---

**Happy Planet Hunting! ğŸªâœ¨**

*Built with â¤ï¸ for the exoplanet discovery community*

